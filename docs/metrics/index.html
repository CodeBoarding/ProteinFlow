<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>proteinflow.metrics API documentation</title>
<meta name="description" content="Metrics for evaluating prediction quality." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="shortcut icon" type="image/x-icon" href="adaptyv_logo.png?">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>proteinflow.metrics</code></h1>
</header>
<section id="section-intro">
<p>Metrics for evaluating prediction quality.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Metrics for evaluating prediction quality.&#34;&#34;&#34;

import os

import biotite.structure.io as bsio
import numpy as np
import torch
from torch.nn import functional as F
from tqdm import tqdm

from proteinflow.extra import requires_extra

try:
    import blosum as bl
except ImportError:
    pass
try:
    import esm
except ImportError:
    pass
try:
    from tmtools import tm_align
except ImportError:
    pass
try:
    import ablang
except ImportError:
    pass
try:
    from igfold import IgFoldRunner
except ImportError:
    pass
try:
    from ImmuneBuilder import ABodyBuilder2, NanoBodyBuilder2, TCRBuilder2
except ImportError:
    pass


@requires_extra(&#34;blosum&#34;)
def blosum62_score(seq_before, seq_after):
    &#34;&#34;&#34;Calculate the BLOSUM62 score between two sequences.

    Parameters
    ----------
    seq_before : str
        The sequence before the mutation
    seq_after : str
        The sequence after the mutation

    Returns
    -------
    score : int
        The BLOSUM62 score between the two sequences

    &#34;&#34;&#34;
    assert len(seq_before) == len(seq_after)
    matrix = bl.BLOSUM(62)
    score = 0
    for x_before, x_after in zip(seq_before, seq_after):
        score += matrix[x_before][x_after]
    return score

@requires_extra(&#34;blosum&#34;)
def long_repeat_num(seq, thr=5):
    &#34;&#34;&#34;Calculate the number of long repeats in a sequence.

    Parameters
    ----------
    seq : str
        The sequence to be evaluated.
    thr : int, default 5
        The threshold of the length of a repeat.

    Returns
    -------
    num : int
        The number of long repeats in the sequence.

    &#34;&#34;&#34;
    arr = np.array(list(seq))
    # Find the indices where the array changes its value
    changes = np.flatnonzero(arr[:-1] != arr[1:])
    # Split the array into consecutive groups
    groups = np.split(arr, changes + 1)
    # Filter groups that are longer than N
    long_groups = filter(lambda g: len(g) &gt; thr, groups)
    # Count the number of long groups
    count = sum(1 for _ in long_groups)
    return count


@requires_extra(&#34;esm&#34;, install_name=&#34;fair-esm&#34;)
def _get_esm_model(esm_model_name):
    &#34;&#34;&#34;Get ESM model, batch converter and tok_to_idx dictionary.&#34;&#34;&#34;
    model_dict = {
        &#34;esm2_t6_8M_UR50D&#34;: esm.pretrained.esm2_t6_8M_UR50D,
        &#34;esm2_t12_35M_UR50D&#34;: esm.pretrained.esm2_t12_35M_UR50D,
        &#34;esm2_t30_150M_UR50D&#34;: esm.pretrained.esm2_t30_150M_UR50D,
        &#34;esm2_t33_650M_UR50D&#34;: esm.pretrained.esm2_t33_650M_UR50D,
        &#34;esm2_t36_3B_UR50D&#34;: esm.pretrained.esm2_t36_3B_UR50D,
        &#34;esm2_t48_15B_UR50D&#34;: esm.pretrained.esm2_t48_15B_UR50D,
    }
    esm_model, alphabet = model_dict[esm_model_name]()
    if torch.cuda.is_available():
        esm_model.to(&#34;cuda&#34;)
    batch_converter = alphabet.get_batch_converter()
    tok_to_idx = alphabet.tok_to_idx
    return esm_model, batch_converter, tok_to_idx


@requires_extra(&#34;ablang&#34;)
def ablang_pll(
    sequence,
    predict_mask,
    ablang_model_name=&#34;heavy&#34;,
    average=False,
):
    &#34;&#34;&#34;Compute pseudo log likelihood.

    Note that you need to install `ablang` (see https://github.com/oxpig/AbLang/tree/main).

    Parameters
    ----------
    sequence : str
        Chain sequence (string of amino acid codes)
    predict_mask : np.ndarray
        Predict mask corresponding to the sequence (array of 0 and 1 where 1 indicates a predicted residue)
    ablang_model_name : {&#34;heavy&#34;, &#34;light&#34;}, default &#34;heavy&#34;
        Name of the AbLang model to use
    average : bool, default False
        Whether to average the pseudo log likelihood over the residues

    Returns
    -------
    pll: float
        Pseudo log likelihood

    &#34;&#34;&#34;
    ablang_model = ablang.pretrained(
        ablang_model_name
    )  # Use &#34;light&#34; if you are working with light chains
    ablang_model.freeze()

    sequences = []
    sequence = list(sequence)
    predict_idx = np.where(predict_mask)[0]
    for i in predict_idx:
        sequences.append(&#34;&#34;.join(sequence[:i]) + &#34;*&#34; + &#34;&#34;.join(sequence[i + 1 :]))

    logits = ablang_model(sequences, mode=&#34;likelihood&#34;)[:, 1:]
    exp_logits = np.exp(logits)
    prob = exp_logits / exp_logits.sum(axis=-1, keepdims=True)
    true_idx = [
        ablang_model.tokenizer.vocab_to_token[x] - 1
        for x in np.array(sequence)[predict_idx]
    ]

    prob = prob[range(prob.shape[0]), predict_idx, true_idx]
    pll = np.log(prob).sum()
    if average:
        pll /= len(predict_idx)
    return pll


@requires_extra(&#34;esm&#34;, install_name=&#34;fair-esm&#34;)
def esm_pll(
    chain_sequences,
    predict_masks,
    esm_model_name=&#34;esm2_t30_150M_UR50D&#34;,
    esm_model_objects=None,
    average=False,
):
    &#34;&#34;&#34;Compute pseudo log likelihood.

    Parameters
    ----------
    chain_sequences : list of str
        List of chain sequences (strings of amino acid codes)
    predict_masks : list of np.ndarray
        List of predict masks corresponding to the sequences (arrays of 0 and 1 where 1 indicates a predicted residue)
    esm_model_name : str, default &#34;esm2_t30_150M_UR50D&#34;
        Name of the ESM-2 model to use
    esm_model_objects : tuple, optional
        Tuple of ESM-2 model, batch converter and tok_to_idx dictionary (if not None, `esm_model_name` will be ignored)
    average : bool, default False
        Whether to average the pseudo log likelihood over the residues

    Returns
    -------
    pll: float
        Pseudo log likelihood

    &#34;&#34;&#34;
    predict_mask = []
    for mask in predict_masks:
        predict_mask.append(mask)
        predict_mask.append(np.zeros(2))
    predict_mask = np.concatenate(predict_mask, axis=0)
    predict_idx = np.where(predict_mask)[0]
    sequence = []
    for i, seq in enumerate(chain_sequences):
        sequence += list(seq)
        if i != len(chain_sequences) - 1:
            sequence += [&#34;&lt;eos&gt;&#34;, &#34;&lt;cls&gt;&#34;]

    if esm_model_objects is None:
        esm_model, batch_converter, tok_to_idx = _get_esm_model(esm_model_name)
    else:
        esm_model, batch_converter, tok_to_idx = esm_model_objects
    pll = 0
    for i in predict_idx:
        sequence_ = &#34;&#34;.join(sequence[:i]) + &#34;&lt;mask&gt;&#34; + &#34;&#34;.join(sequence[i + 1 :])
        _, _, batch_tokens = batch_converter([(0, sequence_)])
        if torch.cuda.is_available():
            batch_tokens = batch_tokens.to(&#34;cuda&#34;)
        with torch.no_grad():
            results = esm_model(batch_tokens, repr_layers=[6], return_contacts=False)
        logits = results[&#34;logits&#34;][0, i + 1].detach().cpu()
        tok_idx = tok_to_idx[sequence[i]]
        prob = F.softmax(logits[4:24], dim=-1)[tok_idx - 4]
        pll += torch.log(prob).item()
    if average:
        pll /= len(predict_idx)
    return pll


def ca_rmsd(coordinates1, coordinates2):
    &#34;&#34;&#34;Calculate CA RMSD between two structures.

    Parameters
    ----------
    coordinates1 : np.ndarray
        The CA coordinates array of the first structure, shaped `(L, 3)`
    coordinates2 : ProteinEntry
        The CA coordinates array of the second structure, shaped `(L, 3)`

    Returns
    -------
    rmsd : float
        The RMSD between the two structures

    &#34;&#34;&#34;
    return np.sqrt(((coordinates1 - coordinates2) ** 2).sum(axis=-1).mean())


@requires_extra(&#34;tmtools&#34;)
def tm_score(coordinates1, coordinates2, sequence1, sequence2):
    &#34;&#34;&#34;Calculate TM-score between two structures.

    Parameters
    ----------
    coordinates1 : np.ndarray
        The CA coordinates array of the first structure, shaped `(L, 3)`
    coordinates2 : ProteinEntry
        The CA coordinates array of the second structure, shaped `(L, 3)`
    sequence1 : str
        The sequence of the first structure
    sequence2 : str
        The sequence of the second structure

    Returns
    -------
    tm_score : float
        The TM-score between the two structures

    &#34;&#34;&#34;
    res = tm_align(coordinates1, coordinates2, sequence1, sequence2)
    return (res.tm_norm_chain1 + res.tm_norm_chain2) / 2


@requires_extra(&#34;esm&#34;, install_name=&#34;fair-esm[esmfold]&#34;)
def esmfold_generate(sequences, filepaths=None):
    &#34;&#34;&#34;Generate PDB structures using ESMFold.

    Note that you need to install `fair-esm` with the `esmfold` option (see https://github.com/facebookresearch/esm/tree/main).
    The model also requires &gt; 16GB CPU and GPU memory.

    Parameters
    ----------
    sequences : list of str
        List of sequences to be generated (chains separated with `&#39;:&#39;`)
    filepaths : list of str, default None
        List of filepaths for the generated structures

    &#34;&#34;&#34;
    assert filepaths is None or len(filepaths) == len(sequences)
    print(&#34;Loading the ESMFold model...&#34;)
    model = esm.pretrained.esmfold_v1()
    model = model.eval().cuda()
    print(&#34;Model loaded.&#34;)
    if filepaths is None:
        if not os.path.exists(&#34;esmfold_output&#34;):
            os.mkdir(&#34;esmfold_output&#34;)
        filepaths = [
            os.path.join(&#34;esmfold_output&#34;, f&#34;seq_{i}.pdb&#34;)
            for i in range(len(sequences))
        ]
    with torch.no_grad():
        for sequence, path in tqdm(zip(sequences, filepaths), total=len(sequences)):
            output = model.infer_pdb(sequence)
            with open(path, &#34;w&#34;) as f:
                f.write(output)


@requires_extra(&#34;igfold&#34;)
def igfold_generate(sequence_dicts, filepaths=None, use_openmm=False):
    &#34;&#34;&#34;Generate PDB structures using IgFold.

    Note that you need to install `igfold` (see https://github.com/Graylab/IgFold).

    Parameters
    ----------
    sequence_dicts : list of dict
        List of sequence dictionaries (keys: &#34;H&#34;, &#34;L&#34; for heavy and light chains)
    filepaths : list of str, optional
        List of filepaths for the generated structures
    use_openmm : bool, default False
        Whether to use refinement with OpenMM

    &#34;&#34;&#34;
    assert filepaths is None or len(filepaths) == len(sequence_dicts)
    igfold = IgFoldRunner()
    folder = &#34;igfold_refine_output&#34; if use_openmm else &#34;igfold_output&#34;
    if filepaths is None:
        if not os.path.exists(folder):
            os.mkdir(folder)
        filepaths = [
            os.path.join(folder, f&#34;seq_{i}.pdb&#34;) for i in range(len(sequence_dicts))
        ]
    for seqs, path in tqdm(zip(sequence_dicts, filepaths), total=len(sequence_dicts)):
        igfold.fold(
            path,  # Output PDB file
            sequences=seqs,  # Antibody sequences
            do_refine=use_openmm,  # Refine the antibody structure
            use_openmm=use_openmm,  # Use OpenMM for refinement
            do_renum=False,  # Renumber predicted antibody structure (Chothia)
        )


@requires_extra(&#34;ImmuneBuilder&#34;)
def immunebuilder_generate(sequence_dicts, filepaths=None, protein_type=&#34;antibody&#34;):
    &#34;&#34;&#34;Generate PDB structures using ImmuneBuilder.

    Note that you need to install `immunebuilder` (see https://github.com/oxpig/ImmuneBuilder)

    Parameters
    ----------
    sequence_dicts : list of dict
        List of sequence dictionaries (keys: &#34;H&#34;, &#34;L&#34; for heavy and light chains)
    filepaths : list of str, optional
        List of filepaths for the generated structures
    protein_type: {&#34;antibody&#34;, &#34;nanobody&#34;, &#34;tcr&#34;}
        Type of the structure to generate

    &#34;&#34;&#34;
    predictor_classes = {
        &#34;antibody&#34;: ABodyBuilder2,
        &#34;nanobody&#34;: NanoBodyBuilder2,
        &#34;tcr&#34;: TCRBuilder2,
    }
    predictor = predictor_classes[protein_type]()
    folder = &#34;immunebuilder_output&#34;
    if filepaths is None:
        if not os.path.exists(folder):
            os.mkdir(folder)
        filepaths = [
            os.path.join(folder, f&#34;seq_{i}.pdb&#34;) for i in range(len(sequence_dicts))
        ]
    for seqs, path in tqdm(zip(sequence_dicts, filepaths), total=len(sequence_dicts)):
        out = predictor.predict(seqs)
        out.save(path)


def confidence_from_file(filepath, predict_mask=None):
    &#34;&#34;&#34;Get the average pLDDT or pRMSD score of a structure generated with ESMFold or IgFold.

    This function loads the metric that is stored in the B-factor column of the PDB file.
    For files generated with ESMFold, the metric is pLDDT; for IgFold and ImmuneBuilder, the metric is pRMSD.

    Parameters
    ----------
    filepath : str
        Filepath of the structure
    predict_mask : np.ndarray, default None
        Predict mask of the structure (1 indicates a predicted residue, 0 otherwise)

    Returns
    -------
    confidence : float
        Average PLDDT / pRMSD score of the structure

    &#34;&#34;&#34;
    struct = bsio.load_structure(filepath, extra_fields=[&#34;b_factor&#34;])
    if predict_mask is not None:
        order = -1
        order_array = []
        for i in range(len(struct)):
            if struct[i].atom_name == &#34;N&#34;:
                order += 1
            order_array.append(order)
        b_factor = [
            atom.b_factor
            for order, atom in zip(order_array, struct)
            if predict_mask[order] == 1
        ]
        return np.array(b_factor).mean()
    else:
        return struct.b_factor.mean()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="proteinflow.metrics.ablang_pll"><code class="name flex">
<span>def <span class="ident">ablang_pll</span></span>(<span>sequence, predict_mask, ablang_model_name='heavy', average=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute pseudo log likelihood.</p>
<p>Note that you need to install <code>ablang</code> (see <a href="https://github.com/oxpig/AbLang/tree/main">https://github.com/oxpig/AbLang/tree/main</a>).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sequence</code></strong> :&ensp;<code>str</code></dt>
<dd>Chain sequence (string of amino acid codes)</dd>
<dt><strong><code>predict_mask</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Predict mask corresponding to the sequence (array of 0 and 1 where 1 indicates a predicted residue)</dd>
<dt><strong><code>ablang_model_name</code></strong> :&ensp;<code>{"heavy", "light"}</code>, default <code>"heavy"</code></dt>
<dd>Name of the AbLang model to use</dd>
<dt><strong><code>average</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Whether to average the pseudo log likelihood over the residues</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>pll</code></strong> :&ensp;<code>float</code></dt>
<dd>Pseudo log likelihood</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires_extra(&#34;ablang&#34;)
def ablang_pll(
    sequence,
    predict_mask,
    ablang_model_name=&#34;heavy&#34;,
    average=False,
):
    &#34;&#34;&#34;Compute pseudo log likelihood.

    Note that you need to install `ablang` (see https://github.com/oxpig/AbLang/tree/main).

    Parameters
    ----------
    sequence : str
        Chain sequence (string of amino acid codes)
    predict_mask : np.ndarray
        Predict mask corresponding to the sequence (array of 0 and 1 where 1 indicates a predicted residue)
    ablang_model_name : {&#34;heavy&#34;, &#34;light&#34;}, default &#34;heavy&#34;
        Name of the AbLang model to use
    average : bool, default False
        Whether to average the pseudo log likelihood over the residues

    Returns
    -------
    pll: float
        Pseudo log likelihood

    &#34;&#34;&#34;
    ablang_model = ablang.pretrained(
        ablang_model_name
    )  # Use &#34;light&#34; if you are working with light chains
    ablang_model.freeze()

    sequences = []
    sequence = list(sequence)
    predict_idx = np.where(predict_mask)[0]
    for i in predict_idx:
        sequences.append(&#34;&#34;.join(sequence[:i]) + &#34;*&#34; + &#34;&#34;.join(sequence[i + 1 :]))

    logits = ablang_model(sequences, mode=&#34;likelihood&#34;)[:, 1:]
    exp_logits = np.exp(logits)
    prob = exp_logits / exp_logits.sum(axis=-1, keepdims=True)
    true_idx = [
        ablang_model.tokenizer.vocab_to_token[x] - 1
        for x in np.array(sequence)[predict_idx]
    ]

    prob = prob[range(prob.shape[0]), predict_idx, true_idx]
    pll = np.log(prob).sum()
    if average:
        pll /= len(predict_idx)
    return pll</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.blosum62_score"><code class="name flex">
<span>def <span class="ident">blosum62_score</span></span>(<span>seq_before, seq_after)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the BLOSUM62 score between two sequences.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>seq_before</code></strong> :&ensp;<code>str</code></dt>
<dd>The sequence before the mutation</dd>
<dt><strong><code>seq_after</code></strong> :&ensp;<code>str</code></dt>
<dd>The sequence after the mutation</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>score</code></strong> :&ensp;<code>int</code></dt>
<dd>The BLOSUM62 score between the two sequences</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires_extra(&#34;blosum&#34;)
def blosum62_score(seq_before, seq_after):
    &#34;&#34;&#34;Calculate the BLOSUM62 score between two sequences.

    Parameters
    ----------
    seq_before : str
        The sequence before the mutation
    seq_after : str
        The sequence after the mutation

    Returns
    -------
    score : int
        The BLOSUM62 score between the two sequences

    &#34;&#34;&#34;
    assert len(seq_before) == len(seq_after)
    matrix = bl.BLOSUM(62)
    score = 0
    for x_before, x_after in zip(seq_before, seq_after):
        score += matrix[x_before][x_after]
    return score</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.ca_rmsd"><code class="name flex">
<span>def <span class="ident">ca_rmsd</span></span>(<span>coordinates1, coordinates2)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate CA RMSD between two structures.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>coordinates1</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The CA coordinates array of the first structure, shaped <code>(L, 3)</code></dd>
<dt><strong><code>coordinates2</code></strong> :&ensp;<code>ProteinEntry</code></dt>
<dd>The CA coordinates array of the second structure, shaped <code>(L, 3)</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>rmsd</code></strong> :&ensp;<code>float</code></dt>
<dd>The RMSD between the two structures</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ca_rmsd(coordinates1, coordinates2):
    &#34;&#34;&#34;Calculate CA RMSD between two structures.

    Parameters
    ----------
    coordinates1 : np.ndarray
        The CA coordinates array of the first structure, shaped `(L, 3)`
    coordinates2 : ProteinEntry
        The CA coordinates array of the second structure, shaped `(L, 3)`

    Returns
    -------
    rmsd : float
        The RMSD between the two structures

    &#34;&#34;&#34;
    return np.sqrt(((coordinates1 - coordinates2) ** 2).sum(axis=-1).mean())</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.confidence_from_file"><code class="name flex">
<span>def <span class="ident">confidence_from_file</span></span>(<span>filepath, predict_mask=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the average pLDDT or pRMSD score of a structure generated with ESMFold or IgFold.</p>
<p>This function loads the metric that is stored in the B-factor column of the PDB file.
For files generated with ESMFold, the metric is pLDDT; for IgFold and ImmuneBuilder, the metric is pRMSD.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Filepath of the structure</dd>
<dt><strong><code>predict_mask</code></strong> :&ensp;<code>np.ndarray</code>, default <code>None</code></dt>
<dd>Predict mask of the structure (1 indicates a predicted residue, 0 otherwise)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>confidence</code></strong> :&ensp;<code>float</code></dt>
<dd>Average PLDDT / pRMSD score of the structure</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def confidence_from_file(filepath, predict_mask=None):
    &#34;&#34;&#34;Get the average pLDDT or pRMSD score of a structure generated with ESMFold or IgFold.

    This function loads the metric that is stored in the B-factor column of the PDB file.
    For files generated with ESMFold, the metric is pLDDT; for IgFold and ImmuneBuilder, the metric is pRMSD.

    Parameters
    ----------
    filepath : str
        Filepath of the structure
    predict_mask : np.ndarray, default None
        Predict mask of the structure (1 indicates a predicted residue, 0 otherwise)

    Returns
    -------
    confidence : float
        Average PLDDT / pRMSD score of the structure

    &#34;&#34;&#34;
    struct = bsio.load_structure(filepath, extra_fields=[&#34;b_factor&#34;])
    if predict_mask is not None:
        order = -1
        order_array = []
        for i in range(len(struct)):
            if struct[i].atom_name == &#34;N&#34;:
                order += 1
            order_array.append(order)
        b_factor = [
            atom.b_factor
            for order, atom in zip(order_array, struct)
            if predict_mask[order] == 1
        ]
        return np.array(b_factor).mean()
    else:
        return struct.b_factor.mean()</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.esm_pll"><code class="name flex">
<span>def <span class="ident">esm_pll</span></span>(<span>chain_sequences, predict_masks, esm_model_name='esm2_t30_150M_UR50D', esm_model_objects=None, average=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute pseudo log likelihood.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>chain_sequences</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>List of chain sequences (strings of amino acid codes)</dd>
<dt><strong><code>predict_masks</code></strong> :&ensp;<code>list</code> of <code>np.ndarray</code></dt>
<dd>List of predict masks corresponding to the sequences (arrays of 0 and 1 where 1 indicates a predicted residue)</dd>
<dt><strong><code>esm_model_name</code></strong> :&ensp;<code>str</code>, default <code>"esm2_t30_150M_UR50D"</code></dt>
<dd>Name of the ESM-2 model to use</dd>
<dt><strong><code>esm_model_objects</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>Tuple of ESM-2 model, batch converter and tok_to_idx dictionary (if not None, <code>esm_model_name</code> will be ignored)</dd>
<dt><strong><code>average</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Whether to average the pseudo log likelihood over the residues</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>pll</code></strong> :&ensp;<code>float</code></dt>
<dd>Pseudo log likelihood</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires_extra(&#34;esm&#34;, install_name=&#34;fair-esm&#34;)
def esm_pll(
    chain_sequences,
    predict_masks,
    esm_model_name=&#34;esm2_t30_150M_UR50D&#34;,
    esm_model_objects=None,
    average=False,
):
    &#34;&#34;&#34;Compute pseudo log likelihood.

    Parameters
    ----------
    chain_sequences : list of str
        List of chain sequences (strings of amino acid codes)
    predict_masks : list of np.ndarray
        List of predict masks corresponding to the sequences (arrays of 0 and 1 where 1 indicates a predicted residue)
    esm_model_name : str, default &#34;esm2_t30_150M_UR50D&#34;
        Name of the ESM-2 model to use
    esm_model_objects : tuple, optional
        Tuple of ESM-2 model, batch converter and tok_to_idx dictionary (if not None, `esm_model_name` will be ignored)
    average : bool, default False
        Whether to average the pseudo log likelihood over the residues

    Returns
    -------
    pll: float
        Pseudo log likelihood

    &#34;&#34;&#34;
    predict_mask = []
    for mask in predict_masks:
        predict_mask.append(mask)
        predict_mask.append(np.zeros(2))
    predict_mask = np.concatenate(predict_mask, axis=0)
    predict_idx = np.where(predict_mask)[0]
    sequence = []
    for i, seq in enumerate(chain_sequences):
        sequence += list(seq)
        if i != len(chain_sequences) - 1:
            sequence += [&#34;&lt;eos&gt;&#34;, &#34;&lt;cls&gt;&#34;]

    if esm_model_objects is None:
        esm_model, batch_converter, tok_to_idx = _get_esm_model(esm_model_name)
    else:
        esm_model, batch_converter, tok_to_idx = esm_model_objects
    pll = 0
    for i in predict_idx:
        sequence_ = &#34;&#34;.join(sequence[:i]) + &#34;&lt;mask&gt;&#34; + &#34;&#34;.join(sequence[i + 1 :])
        _, _, batch_tokens = batch_converter([(0, sequence_)])
        if torch.cuda.is_available():
            batch_tokens = batch_tokens.to(&#34;cuda&#34;)
        with torch.no_grad():
            results = esm_model(batch_tokens, repr_layers=[6], return_contacts=False)
        logits = results[&#34;logits&#34;][0, i + 1].detach().cpu()
        tok_idx = tok_to_idx[sequence[i]]
        prob = F.softmax(logits[4:24], dim=-1)[tok_idx - 4]
        pll += torch.log(prob).item()
    if average:
        pll /= len(predict_idx)
    return pll</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.esmfold_generate"><code class="name flex">
<span>def <span class="ident">esmfold_generate</span></span>(<span>sequences, filepaths=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate PDB structures using ESMFold.</p>
<p>Note that you need to install <code>fair-esm</code> with the <code>esmfold</code> option (see <a href="https://github.com/facebookresearch/esm/tree/main">https://github.com/facebookresearch/esm/tree/main</a>).
The model also requires &gt; 16GB CPU and GPU memory.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sequences</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>List of sequences to be generated (chains separated with <code>':'</code>)</dd>
<dt><strong><code>filepaths</code></strong> :&ensp;<code>list</code> of <code>str</code>, default <code>None</code></dt>
<dd>List of filepaths for the generated structures</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires_extra(&#34;esm&#34;, install_name=&#34;fair-esm[esmfold]&#34;)
def esmfold_generate(sequences, filepaths=None):
    &#34;&#34;&#34;Generate PDB structures using ESMFold.

    Note that you need to install `fair-esm` with the `esmfold` option (see https://github.com/facebookresearch/esm/tree/main).
    The model also requires &gt; 16GB CPU and GPU memory.

    Parameters
    ----------
    sequences : list of str
        List of sequences to be generated (chains separated with `&#39;:&#39;`)
    filepaths : list of str, default None
        List of filepaths for the generated structures

    &#34;&#34;&#34;
    assert filepaths is None or len(filepaths) == len(sequences)
    print(&#34;Loading the ESMFold model...&#34;)
    model = esm.pretrained.esmfold_v1()
    model = model.eval().cuda()
    print(&#34;Model loaded.&#34;)
    if filepaths is None:
        if not os.path.exists(&#34;esmfold_output&#34;):
            os.mkdir(&#34;esmfold_output&#34;)
        filepaths = [
            os.path.join(&#34;esmfold_output&#34;, f&#34;seq_{i}.pdb&#34;)
            for i in range(len(sequences))
        ]
    with torch.no_grad():
        for sequence, path in tqdm(zip(sequences, filepaths), total=len(sequences)):
            output = model.infer_pdb(sequence)
            with open(path, &#34;w&#34;) as f:
                f.write(output)</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.igfold_generate"><code class="name flex">
<span>def <span class="ident">igfold_generate</span></span>(<span>sequence_dicts, filepaths=None, use_openmm=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate PDB structures using IgFold.</p>
<p>Note that you need to install <code>igfold</code> (see <a href="https://github.com/Graylab/IgFold">https://github.com/Graylab/IgFold</a>).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sequence_dicts</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>List of sequence dictionaries (keys: "H", "L" for heavy and light chains)</dd>
<dt><strong><code>filepaths</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional</dt>
<dd>List of filepaths for the generated structures</dd>
<dt><strong><code>use_openmm</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Whether to use refinement with OpenMM</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires_extra(&#34;igfold&#34;)
def igfold_generate(sequence_dicts, filepaths=None, use_openmm=False):
    &#34;&#34;&#34;Generate PDB structures using IgFold.

    Note that you need to install `igfold` (see https://github.com/Graylab/IgFold).

    Parameters
    ----------
    sequence_dicts : list of dict
        List of sequence dictionaries (keys: &#34;H&#34;, &#34;L&#34; for heavy and light chains)
    filepaths : list of str, optional
        List of filepaths for the generated structures
    use_openmm : bool, default False
        Whether to use refinement with OpenMM

    &#34;&#34;&#34;
    assert filepaths is None or len(filepaths) == len(sequence_dicts)
    igfold = IgFoldRunner()
    folder = &#34;igfold_refine_output&#34; if use_openmm else &#34;igfold_output&#34;
    if filepaths is None:
        if not os.path.exists(folder):
            os.mkdir(folder)
        filepaths = [
            os.path.join(folder, f&#34;seq_{i}.pdb&#34;) for i in range(len(sequence_dicts))
        ]
    for seqs, path in tqdm(zip(sequence_dicts, filepaths), total=len(sequence_dicts)):
        igfold.fold(
            path,  # Output PDB file
            sequences=seqs,  # Antibody sequences
            do_refine=use_openmm,  # Refine the antibody structure
            use_openmm=use_openmm,  # Use OpenMM for refinement
            do_renum=False,  # Renumber predicted antibody structure (Chothia)
        )</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.immunebuilder_generate"><code class="name flex">
<span>def <span class="ident">immunebuilder_generate</span></span>(<span>sequence_dicts, filepaths=None, protein_type='antibody')</span>
</code></dt>
<dd>
<div class="desc"><p>Generate PDB structures using ImmuneBuilder.</p>
<p>Note that you need to install <code>immunebuilder</code> (see <a href="https://github.com/oxpig/ImmuneBuilder">https://github.com/oxpig/ImmuneBuilder</a>)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sequence_dicts</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>List of sequence dictionaries (keys: "H", "L" for heavy and light chains)</dd>
<dt><strong><code>filepaths</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional</dt>
<dd>List of filepaths for the generated structures</dd>
<dt><strong><code>protein_type</code></strong> :&ensp;<code>{"antibody", "nanobody", "tcr"}</code></dt>
<dd>Type of the structure to generate</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires_extra(&#34;ImmuneBuilder&#34;)
def immunebuilder_generate(sequence_dicts, filepaths=None, protein_type=&#34;antibody&#34;):
    &#34;&#34;&#34;Generate PDB structures using ImmuneBuilder.

    Note that you need to install `immunebuilder` (see https://github.com/oxpig/ImmuneBuilder)

    Parameters
    ----------
    sequence_dicts : list of dict
        List of sequence dictionaries (keys: &#34;H&#34;, &#34;L&#34; for heavy and light chains)
    filepaths : list of str, optional
        List of filepaths for the generated structures
    protein_type: {&#34;antibody&#34;, &#34;nanobody&#34;, &#34;tcr&#34;}
        Type of the structure to generate

    &#34;&#34;&#34;
    predictor_classes = {
        &#34;antibody&#34;: ABodyBuilder2,
        &#34;nanobody&#34;: NanoBodyBuilder2,
        &#34;tcr&#34;: TCRBuilder2,
    }
    predictor = predictor_classes[protein_type]()
    folder = &#34;immunebuilder_output&#34;
    if filepaths is None:
        if not os.path.exists(folder):
            os.mkdir(folder)
        filepaths = [
            os.path.join(folder, f&#34;seq_{i}.pdb&#34;) for i in range(len(sequence_dicts))
        ]
    for seqs, path in tqdm(zip(sequence_dicts, filepaths), total=len(sequence_dicts)):
        out = predictor.predict(seqs)
        out.save(path)</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.long_repeat_num"><code class="name flex">
<span>def <span class="ident">long_repeat_num</span></span>(<span>seq, thr=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the number of long repeats in a sequence.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>seq</code></strong> :&ensp;<code>str</code></dt>
<dd>The sequence to be evaluated.</dd>
<dt><strong><code>thr</code></strong> :&ensp;<code>int</code>, default <code>5</code></dt>
<dd>The threshold of the length of a repeat.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>num</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of long repeats in the sequence.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires_extra(&#34;blosum&#34;)
def long_repeat_num(seq, thr=5):
    &#34;&#34;&#34;Calculate the number of long repeats in a sequence.

    Parameters
    ----------
    seq : str
        The sequence to be evaluated.
    thr : int, default 5
        The threshold of the length of a repeat.

    Returns
    -------
    num : int
        The number of long repeats in the sequence.

    &#34;&#34;&#34;
    arr = np.array(list(seq))
    # Find the indices where the array changes its value
    changes = np.flatnonzero(arr[:-1] != arr[1:])
    # Split the array into consecutive groups
    groups = np.split(arr, changes + 1)
    # Filter groups that are longer than N
    long_groups = filter(lambda g: len(g) &gt; thr, groups)
    # Count the number of long groups
    count = sum(1 for _ in long_groups)
    return count</code></pre>
</details>
</dd>
<dt id="proteinflow.metrics.tm_score"><code class="name flex">
<span>def <span class="ident">tm_score</span></span>(<span>coordinates1, coordinates2, sequence1, sequence2)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate TM-score between two structures.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>coordinates1</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The CA coordinates array of the first structure, shaped <code>(L, 3)</code></dd>
<dt><strong><code>coordinates2</code></strong> :&ensp;<code>ProteinEntry</code></dt>
<dd>The CA coordinates array of the second structure, shaped <code>(L, 3)</code></dd>
<dt><strong><code>sequence1</code></strong> :&ensp;<code>str</code></dt>
<dd>The sequence of the first structure</dd>
<dt><strong><code>sequence2</code></strong> :&ensp;<code>str</code></dt>
<dd>The sequence of the second structure</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tm_score</code></strong> :&ensp;<code>float</code></dt>
<dd>The TM-score between the two structures</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires_extra(&#34;tmtools&#34;)
def tm_score(coordinates1, coordinates2, sequence1, sequence2):
    &#34;&#34;&#34;Calculate TM-score between two structures.

    Parameters
    ----------
    coordinates1 : np.ndarray
        The CA coordinates array of the first structure, shaped `(L, 3)`
    coordinates2 : ProteinEntry
        The CA coordinates array of the second structure, shaped `(L, 3)`
    sequence1 : str
        The sequence of the first structure
    sequence2 : str
        The sequence of the second structure

    Returns
    -------
    tm_score : float
        The TM-score between the two structures

    &#34;&#34;&#34;
    res = tm_align(coordinates1, coordinates2, sequence1, sequence2)
    return (res.tm_norm_chain1 + res.tm_norm_chain2) / 2</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="pdoc Home" href="https://adaptyvbio.github.io/ProteinFlow/">
<img src="https://raw.githubusercontent.com/adaptyvbio/ProteinFlow/main/media/proteinflow_logo.png" alt="">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="proteinflow" href="../index.html">proteinflow</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="proteinflow.metrics.ablang_pll" href="#proteinflow.metrics.ablang_pll">ablang_pll</a></code></li>
<li><code><a title="proteinflow.metrics.blosum62_score" href="#proteinflow.metrics.blosum62_score">blosum62_score</a></code></li>
<li><code><a title="proteinflow.metrics.ca_rmsd" href="#proteinflow.metrics.ca_rmsd">ca_rmsd</a></code></li>
<li><code><a title="proteinflow.metrics.confidence_from_file" href="#proteinflow.metrics.confidence_from_file">confidence_from_file</a></code></li>
<li><code><a title="proteinflow.metrics.esm_pll" href="#proteinflow.metrics.esm_pll">esm_pll</a></code></li>
<li><code><a title="proteinflow.metrics.esmfold_generate" href="#proteinflow.metrics.esmfold_generate">esmfold_generate</a></code></li>
<li><code><a title="proteinflow.metrics.igfold_generate" href="#proteinflow.metrics.igfold_generate">igfold_generate</a></code></li>
<li><code><a title="proteinflow.metrics.immunebuilder_generate" href="#proteinflow.metrics.immunebuilder_generate">immunebuilder_generate</a></code></li>
<li><code><a title="proteinflow.metrics.long_repeat_num" href="#proteinflow.metrics.long_repeat_num">long_repeat_num</a></code></li>
<li><code><a title="proteinflow.metrics.tm_score" href="#proteinflow.metrics.tm_score">tm_score</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>